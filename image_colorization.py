# -*- coding: utf-8 -*-
"""reverse_oldify.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1pbvEjkDIZolNaMIRKqI5iqYSVRpZVq3i
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import matplotlib.pyplot as plt
import tensorflow as tf
# %matplotlib inline
import cv2
import skimage.color as sk
import os
import keras_tuner as kt
from keras.optimizers import Adam
from keras import metrics
from datetime import datetime
from keras.callbacks import TensorBoard
import keras

IMAGE_SIZE = (224, 224)
BATCH_SIZE = 16
model_id= datetime.now().strftime("%Y%m%d_%H%M%S")
result_path = os.path.join('results', 'colorization', model_id)
if os.path.exists(result_path) == False:
    os.makedirs(result_path)

path = "../root/dataset/images/"
os.environ['TF_GPU_ALLOCATOR'] = 'cuda_malloc_async'
tf.keras.backend.clear_session()
train_gen = tf.keras.preprocessing.image.ImageDataGenerator(
    rescale=1/255.0, validation_split=0.15)

train = train_gen.flow_from_directory(path, target_size=(IMAGE_SIZE[0], IMAGE_SIZE[1]),
                                      batch_size=BATCH_SIZE, class_mode=None, subset="training")

val = train_gen.flow_from_directory(path, target_size=(IMAGE_SIZE[0], IMAGE_SIZE[1]),
                                    batch_size=BATCH_SIZE, class_mode=None, subset="validation")

train_bs = int(train.n/BATCH_SIZE)
val_bs = int(val.n/BATCH_SIZE)
print("batch_sizes", train_bs, val_bs)


def convert_lab(image):
  lab_image = sk.rgb2lab(image)
  return lab_image


def convert_rgb(image):
  rgb_image = sk.lab2rgb(image)
  return rgb_image


def plot_image(image):
  plt.figure(figsize=(12, 8))
  plt.imshow(image, cmap="gray")
  plt.grid(False)
  plt.show()
  plt.close()

def model_builder():
   # Encoder
    input_shape = (7, 7, 512)
    i = tf.keras.layers.Input(shape = input_shape)  

    #decoder
    output = tf.keras.layers.Conv2D(filters = 128, kernel_size= (3,3), padding = "same", activation= "relu")(i)
    output = tf.keras.layers.Conv2D(filters = 128, kernel_size= (3,3), padding = "same", activation= "relu")(i)
    output = tf.keras.layers.Conv2D(filters = 128, kernel_size= (3,3), padding = "same", activation= "relu")(i)
    output = tf.keras.layers.UpSampling2D((2, 2))(output)
    output = tf.keras.layers.Conv2D(filters = 64, kernel_size= (3,3), padding = "same", activation= "relu")(output)
    output = tf.keras.layers.Conv2D(filters = 64, kernel_size= (3,3), padding = "same", activation= "relu")(output)
    output = tf.keras.layers.Conv2D(filters = 64, kernel_size= (3,3), padding = "same", activation= "relu")(output)
    output = tf.keras.layers.UpSampling2D((2, 2))(output)
    output = tf.keras.layers.Conv2D(filters = 32, kernel_size= (3,3), padding = "same", activation= "relu")(output)
    output = tf.keras.layers.Conv2D(filters = 32, kernel_size= (3,3), padding = "same", activation= "relu")(output)
    output = tf.keras.layers.Conv2D(filters = 32, kernel_size= (3,3), padding = "same", activation= "relu")(output)
    output = tf.keras.layers.UpSampling2D((2, 2))(output)
    output = tf.keras.layers.Conv2D(filters = 16, kernel_size= (3,3), padding = "same", activation= "relu")(output)
    output = tf.keras.layers.Conv2D(filters = 16, kernel_size= (3,3), padding = "same", activation= "relu")(output)
    output = tf.keras.layers.Conv2D(filters = 16, kernel_size= (3,3), padding = "same", activation= "relu")(output)
    output = tf.keras.layers.UpSampling2D((2, 2))(output)
    output = tf.keras.layers.Conv2D(filters = 2, kernel_size= (3,3), padding = "same", activation= "tanh")(output)
    output = tf.keras.layers.UpSampling2D((2, 2))(output)

    model = tf.keras.models.Model(inputs = i, outputs = output)

    learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4, 1e-5, 1e-6, 1e-7])
    optimizer = Adam(learning_rate=learning_rate)

    model.compile(
        # loss="binary_crossentropy",
        loss=hp.Choice("loss", ["binary_crossentropy", "mse"]),
        optimizer=optimizer,
        metrics=['accuracy', metrics.Precision(), metrics.Recall()]
    )
    return model

print("loading dataset")
x_train = []
y_train = []
for i in range(train_bs):
    if i % 100 == 0:
        print(i)
    for image in train[i]:
        try:
            lab_image = convert_lab(image)
            x_train.append(lab_image[:, :, 0])
            y_train.append(lab_image[:, :, 1:] / 128)
        except:
            print("Unexpected error. Maybe broken image.")
print("train loaded")
x_train = np.array(x_train)
y_train = np.array(y_train)
print(x_train.shape)
print(y_train.shape)

x_val = []
y_val = []
print("loading validation")
for i in range(val_bs):
    if i % 1000 == 0:
        print(i)
    for image in val[i]:
        try:
            lab_image = convert_lab(image)
            x_val.append(lab_image[:, :, 0])
            y_val.append(lab_image[:, :, 1:] / 128)
        except:
            print("Unexpected error. Maybe broken image.")
print("validation loaded")
x_val = np.array(x_val)
y_val = np.array(y_val)
print(x_val.shape)
print(y_val.shape)

x_train = x_train.reshape(x_train.shape[0], IMAGE_SIZE[0], IMAGE_SIZE[1], 1)
x_val = x_val.reshape(x_val.shape[0], IMAGE_SIZE[0], IMAGE_SIZE[1], 1)
print(x_train.shape)
print(y_train.shape)
print(x_val.shape)
print(y_val.shape)

print("saving data")
np.save("image_colorization/x_train", x_train)
np.save("image_colorization/y_train", y_train)
np.save("image_colorization/x_val", x_val)
np.save("image_colorization/y_val", y_val)

# print("loading data")
# x_train = np.load("image_colorization/x_train.npy")
# y_train = np.load("image_colorization/y_train.npy")
# x_val = np.load("image_colorization/x_val.npy")
# y_val = np.load("image_colorization/y_val.npy")
# print("data_loaded")

reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor="val_accuracy", factor=0.5, patience=10,
                                                 min_lr=0.000001, verbose=1)
print("learning rate reducing")
monitor_es = tf.keras.callbacks.EarlyStopping(
    monitor="val_loss", patience=3, restore_best_weights=False, verbose=True)
checkpoint = checkpoint = tf.keras.callbacks.ModelCheckpoint(os.path.join(".", 'best_scores', 'model_fine_ep{epoch}_valaccuracy{accuracy:.3f}.h5'), 
                             monitor='val_accuracy', 
                             verbose=1, 
                             save_best_only= True, 
                             mode='min')
log_dir = os.path.join(".",result_path, 'Graph', 'Adam')
tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1, write_graph=True, write_images=True)
print("early stopping")

# transfer learning
with tf.device("/device:GPU:0"):
    print("beginning transfer learning")
    vgg_model = tf.keras.applications.vgg16.VGG16()
    transfer_learned_encoder_model = tf.keras.models.Sequential()
    print("getting layers")
    for i, layer in enumerate(vgg_model.layers):
        if i < 19:
            transfer_learned_encoder_model.add(layer)
    for layer in transfer_learned_encoder_model.layers:
        layer.trainable = False

    transfer_learned_encoder_model.summary()

    vgg_features = []
    val_vgg_features = []
    for i, image in enumerate(x_train):
        image = cv2.merge((image, image, image))
        image = image.reshape((1, IMAGE_SIZE[0], IMAGE_SIZE[1], 3))
        prediction = transfer_learned_encoder_model.predict(image)
        prediction = prediction.reshape((7, 7, 512))
        vgg_features.append(prediction)
    vgg_features = np.array(vgg_features)
    print(vgg_features.shape)
    for i, image in enumerate(x_val):
        image = cv2.merge((image, image, image))
        image = image.reshape((1, IMAGE_SIZE[0], IMAGE_SIZE[1], 3))
        prediction = transfer_learned_encoder_model.predict(image)
        prediction = prediction.reshape((7, 7, 512))
        val_vgg_features.append(prediction)
    val_vgg_features = np.array(val_vgg_features)
    print(val_vgg_features.shape)
    transfer_learned_encoder_model.save('encoder/vgg16_encoder.h5')
    

    EPOCHS = 200
    border = int(len(vgg_features) * 0.8)
    train = vgg_features[:border]
    val = vgg_features[border:]
    train_y = y_train[:border]
    val_y = y_train[border:]
    tuner = kt.RandomSearch(
        model_builder,
        objective='val_accuracy',
        max_trials=50,  # Number of different hyperparameter combinations to try
        executions_per_trial=5,
        directory='result_path',  # Directory to save results
        project_name='img colorization'  # Name of the project
    )
    tuner.search(train, train_y, epochs=10, validation_split=0.35, callbacks=[monitor_es])
    best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]
    decoder_model = tuner.hypermodel.build(best_hps)
    decoder_model.summary()
    history = decoder_model.fit(train, train_y, epochs=EPOCHS, validation_data=(val, val_y), verbose=1,
                              callbacks=[reduce_lr, monitor_es,checkpoint, tensorboard_callback], batch_size=16)

    transfer_learned_encoder_model.save(
        'encoder/vgg16_encoder.h5')
    decoder_model.save('decoder/decoder'+model_id+'.h5')
